{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NASA](http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg)\n",
    "\n",
    "---\n",
    "\n",
    "# The Future\n",
    "\n",
    "### GSFC Intermediate/Advanced Python Bootcamp 2017\n",
    "\n",
    "#### Brent Smith\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Back to the Future](http://pbs.twimg.com/media/CR1_f8sWwAA3qjB.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Compatibility\n",
    "\n",
    "---\n",
    "\n",
    "One of the biggest debates within the Python community is choosing Python 2.x or Python 3.x. From the 2016 PyCon keynote from Guido van Rossum ([link](http://youtu.be/YgtL4S7Hrwo)), Python 2.7 was announced to be the last of the 2.x series.\n",
    "\n",
    "Even more evidence: [http://pythonclock.org](https://pythonclock.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got Python 2?\n",
    "\n",
    "---\n",
    "\n",
    "If you have code that is still in Python 2.x, there is a very useful guide to help you transition your code.\n",
    "\n",
    "Details:\n",
    "\n",
    "* [Python-Future](http://python-future.org)\n",
    "* [Six: Python 2 and 3 Compatibility Library](http://pythonhosted.org/six/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Synopsis\n",
    "\n",
    "---\n",
    "\n",
    "* `print` is a function, not a statement\n",
    "  * Python 2.x: ```print 'Hello',```\n",
    "  * Python 3.x: ```print('Hello', end='')```\n",
    "* Strings ([unicode link](http://docs.python.org/3/howto/unicode.html)):\n",
    "  * Python 2.x: str has no encoding (not utf-8)\n",
    "  * Python 3.x: str is unicode\n",
    "* Division:\n",
    "  * Python 2.x: 3/2 = 1\n",
    "  * Python 3.x: 3/2 = 1.5\n",
    "* Others: exceptions, class definitions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python 2/3 Compatible Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "print(\n",
    "    'A new print function using Python 2.',\n",
    "    end='...err {result}.'.format(result=3/2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Formatting Strings Reference](http://pyformat.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. New Stuff...The Future!\n",
    "\n",
    "---\n",
    "\n",
    "Included is a small showcase of 4 new packages (to me) in Python for scientific/engineering applications:\n",
    "\n",
    "* [asyncio](http://docs.python.org/3/library/asyncio.html) - asynchronous/concurrent computing (single-thread)\n",
    "* [xarray](http://xarray.pydata.org/en/stable/) - pandas, but for N-dimensional arrays\n",
    "* [bokeh](http://bokeh.pydata.org/en/latest/) - interactive visualizations\n",
    "* [dask](http://dask.pydata.org/en/latest/) - parallel and distributed computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 asyncio\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Bokeh\n",
    "\n",
    "---\n",
    "\n",
    "Python visualization package aimed at web browsers/sites for interactivity and display. It uses json to send the data to the browser and then uses javascript ([BokehJS](http://bokeh.pydata.org/en/latest/docs/dev_guide/bokehjs.html)) to add interactivity.\n",
    "\n",
    "_Note:_ Output can be to a web page, the Jupyter notebook (inline), or even a local Bokeh server (think dashboards, visualizing large datasets).\n",
    "\n",
    "__Links:__\n",
    "\n",
    "* [Official Gallery](http://bokeh.pydata.org/en/latest/docs/gallery.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.1.1 Charts__\n",
    "\n",
    "Bokeh charts are primarily used for statistical plots such as a histogram, pie (donut) chart, box plot, etc. These are very useful when needing to visualize your data quickly and dynamically (think monitoring data trends through a dashboard of visualizations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Charts Diagram](http://chdoig.github.io/pyladiesatx-bokeh-tutorial/images/charts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sample Data:__ We need some data to work with, so Bokeh provides the interface to download some sample datasets that we can use for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "bokeh.sampledata.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example from: http://nbviewer.jupyter.org/github/bokeh/bokeh-notebooks/blob/master/tutorial/10%20-%20charts.ipynb\n",
    "from bokeh.sampledata.iris import flowers\n",
    "flowers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.charts import Scatter, show, output_notebook\n",
    "output_notebook()\n",
    "p = Scatter(flowers, x='petal_length', y='petal_width')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = Scatter(flowers, x='petal_length', y='petal_width', color='species', legend='top_left')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.1.2 Plotting__\n",
    "\n",
    "---\n",
    "\n",
    "The most popular use of Bokeh is it's plotting interface. This is different than charts in that plotting is centered at the way you plot data (not by a specific type of plot, think boxes rather than circles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Plotting Diagram](http://chdoig.github.io/pyladiesatx-bokeh-tutorial/images/plotting.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example from: http://bokeh.pydata.org/en/latest/docs/gallery/texas.html\n",
    "from bokeh.io import show\n",
    "from bokeh.models import (\n",
    "    ColumnDataSource,\n",
    "    HoverTool,\n",
    "    LogColorMapper\n",
    ")\n",
    "from bokeh.palettes import Viridis6 as palette\n",
    "from bokeh.plotting import figure, output_notebook\n",
    "\n",
    "from bokeh.sampledata.us_counties import data as counties\n",
    "from bokeh.sampledata.unemployment import data as unemployment\n",
    "\n",
    "palette.reverse()\n",
    "\n",
    "counties = {\n",
    "    code: county for code, county in counties.items() if county[\"state\"] == \"tx\"\n",
    "}\n",
    "\n",
    "county_xs = [county[\"lons\"] for county in counties.values()]\n",
    "county_ys = [county[\"lats\"] for county in counties.values()]\n",
    "\n",
    "county_names = [county['name'] for county in counties.values()]\n",
    "county_rates = [unemployment[county_id] for county_id in counties]\n",
    "color_mapper = LogColorMapper(palette=palette)\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "    x=county_xs,\n",
    "    y=county_ys,\n",
    "    name=county_names,\n",
    "    rate=county_rates,\n",
    "))\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,reset,hover,save\"\n",
    "\n",
    "p = figure(\n",
    "    title=\"Texas Unemployment, 2009\", tools=TOOLS,\n",
    "    x_axis_location=None, y_axis_location=None\n",
    ")\n",
    "p.grid.grid_line_color = None\n",
    "\n",
    "p.patches('x', 'y', source=source,\n",
    "          fill_color={'field': 'rate', 'transform': color_mapper},\n",
    "          fill_alpha=0.7, line_color=\"white\", line_width=0.5)\n",
    "\n",
    "hover = p.select_one(HoverTool)\n",
    "hover.point_policy = \"follow_mouse\"\n",
    "hover.tooltips = [\n",
    "    (\"Name\", \"@name\"),\n",
    "    (\"Unemployment rate)\", \"@rate%\"),\n",
    "    (\"(Long, Lat)\", \"($x, $y)\"),\n",
    "]\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.1.3 Models__\n",
    "\n",
    "---\n",
    "\n",
    "The underlying objects that create a Bokeh plot or chart (i.e., Object-Oriented Programming entry point to Bokeh)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Models Part 1](http://chdoig.github.io/pyladiesatx-bokeh-tutorial/images/models1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Models Part 2](http://chdoig.github.io/pyladiesatx-bokeh-tutorial/images/models2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xarray\n",
    "\n",
    "---\n",
    "\n",
    "Brings the power of Pandas to N-dimensional variants of the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "xr.DataArray(np.random.randn(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = xr.DataArray(np.random.randn(2, 3), coords={'x': ['a', 'b']}, dims=('x', 'y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dask\n",
    "\n",
    "---\n",
    "\n",
    "Parallelization and distributed computing is hard to grasp because we weren't taught that at the beginning (i.e., debugging, developing, etc. but for distributed systems is hard).\n",
    "\n",
    "Talk from Plotcon/SciPy by Matthew Rocklin.\n",
    "\n",
    "In a nutshell:\n",
    "* Parallel computing library for Python\n",
    "* Task scheduler (low-latency ~10ms)\n",
    "* Uses other packages to aid (PyData ecosystem): numpy, pandas, etc.\n",
    "* Can be scaled (laptop to supercomputer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import random\n",
    "\n",
    "def inc(x):\n",
    "    sleep(0.2)\n",
    "    return x + 1\n",
    "\n",
    "def double(x):\n",
    "    sleep(0.2)\n",
    "    return 2 * x\n",
    "\n",
    "def add(x,y):\n",
    "    sleep(0.2)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "out = []\n",
    "for x in data:\n",
    "    y = inc(x)\n",
    "    z = double(y)\n",
    "    out.append(z)\n",
    "    \n",
    "total = 0\n",
    "for z in out:\n",
    "    total = add(total, z)\n",
    "\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to parallelize in dask..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "# delayed means to setup but not compute yet\n",
    "inc = dask.delayed(inc)\n",
    "double = dask.delayed(double)\n",
    "add = dask.delayed(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = inc(1)\n",
    "y = inc(2)\n",
    "z = add(x, y)\n",
    "dask.visualize(z, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.compute(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "out = []\n",
    "for x in data:\n",
    "    y = inc(x)\n",
    "    z = double(y)\n",
    "    out.append(z)\n",
    "    \n",
    "total = 0\n",
    "for z in out:\n",
    "    total = add(total, z)\n",
    "\n",
    "# faster due to parallelization\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(total, rankdir='LR') # sequential dependence still evident by visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "out = []\n",
    "for x in data:\n",
    "    y = inc(x)\n",
    "    z = double(y)\n",
    "    out.append(z)\n",
    "    \n",
    "# tree reduction\n",
    "while len(out) > 1:\n",
    "    out = [add(out[i], out[i+1]) for i in range(0, len(out), 2)]\n",
    "\n",
    "total = out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(total, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instantly see which of these two algorithms will be better for parallelization. But what if we had..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "# 15x15 array of ones chunked into 5x5 squares (uses NumPy mainly)\n",
    "x = da.ones((15, 15), chunks=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize((x.dot(x.T) - x.mean(axis=0)).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is bulky. We need a way to visualize how it __performs__ on a system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "c = Client('128.154.200.69:8786')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "from time import sleep\n",
    "import random\n",
    "import dask\n",
    "\n",
    "def inc(x):\n",
    "    sleep(random.random() / 10)\n",
    "    return x + 1\n",
    "\n",
    "def dec(x):\n",
    "    sleep(random.random() / 10)\n",
    "    return x - 1\n",
    "\n",
    "def add(x, y):\n",
    "    sleep(random.random() / 10)\n",
    "    return x + y\n",
    "\n",
    "\n",
    "client = Client('128.154.200.69:8786')\n",
    "\n",
    "incs = client.map(inc, range(100))\n",
    "decs = client.map(dec, range(100))\n",
    "adds = client.map(add, incs, decs)\n",
    "total = client.submit(sum, adds)\n",
    "\n",
    "del incs, decs, adds\n",
    "total.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
